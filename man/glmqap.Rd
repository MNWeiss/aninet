% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/glmqap.R
\name{glmqap}
\alias{glmqap}
\title{Generalised Linear Model Quadratic Assignment Procedure}
\usage{
glmqap(
  formula,
  family = "gaussian",
  weights = NULL,
  offset = NULL,
  nperm = 1000,
  permutation = "DSP"
)
}
\arguments{
\item{formula}{A \code{glm} style formula describing the model to be fit. All elements of this formula should be square matrices of the same size.}

\item{family}{Either a \code{glm()} family or one of \code{"betar"} or \code{"negbin"}. See Details.}

\item{weights}{Square matrix of weights used for fitting, see Details.}

\item{offset}{Square matrix of offsets for fitting, see Details.}

\item{nperm}{Numeric, number of permutations to perform.}

\item{permutation}{Character specifying what form of permutation to carry out. One of \code{"DSP"}, \code{"Y"}, or \code{"X"}.}
}
\value{
An object of class \code{glmqap}, containing a summary of the fitted model. The coefficients table now contains p-values from the randomizations. In addition to all information normally in the respective model summary objects, the object contains an element called \code{permuted_z}, which is a matrix containing the permuted value of each pivotal statistic for all permutations.
}
\description{
This function fits a generalised linear model of the given family
and assesses the significance of the estimated coefficients using a quadratic assignment procedure.
Multiple types of permutation are provided, with the default being the double semi-partialling method.
}
\details{
NOTE: This function is soft-deprecated as of version 0.2. It has become increasingly clear that these permutation procedures are less informative than other analytical methods, particularly methods using multi-membership random effects. Unless you have a very large dataset that makes fitting a Bayesian model impractical, it is strongly recommended to use \link[aninet]{dyadic_brm} instead.

The multiple regression quadratic assignment procedure (MRQAP) is the canonical method for dyadic regression in social networks. However, this method comes with two major assumptions: The residuals of the response are approximately normal (although the DSP method is fairly robust to violations of this assumption), and the social relationships of all dyads are measured with the same precision.
These assumptions are almost never met in animal social network analyses. Replacing the ordinary least-squares fit used in MRQAP with a GLM allows us to address both of these issues in a theoretically sound way, by specifying error families, offsets, and weights.

The \code{weights} argument allows for specification of sampling weights per dyad. For binomial models (appropriate for association indices), these weights should be the dyadic denominator of the association index.

The \code{offset} argument gives a matrix with a known coefficient of 1 in the model. This will primarily be useful for interaction rates. Here, we can use a count model without an upper bound (by setting \code{family} to be one of \code{"poisson"}, \code{"quasipoisson"}, or \code{"negbin"}), and include the logarithm of dyadic sampling effort as an offset. This means we're using sampling effort as an exposure term, and therefore modelling interaction rates rather than just counts.

In most cases, the model is fit using \link[stats]{glm}. However, if \code{family = "betar"}, the \link[betareg]{betareg} function from the \code{betareg} package is used, and if \code{family = "negbin"}, the \link[MASS]{glm.nb} function from the \code{MASS} package is used.

Beta models will be most useful for association index type data without an integer numerator/denominator (such as measurements of portion time together from biologgers/video). Dyadic sampling effort can still be specified as the weights, but take care.
In \code{betareg()}, weights are treated as sampling, rather than proportional, weights. This means that the function assumes your true sample size is \code{sum(weights)}. While this won't effect your estimate or significance (because we use permutations), it will give
pretty strange results for the standard errors. A solution is to transform your weights such that \code{sum(weights) = length(weights)}.

The function allows multiple types of permutation. The \code{"DSP"} method is the most robust for testing multiple predictors, and is based on the method proposed by Dekker et al. (2007). This explicitly tests the effect of each covariate, controlling for the effect of others and the relationship between variables.
The \code{"Y"} permutation method permutes the response matrix, and tests the null hypothesis that the response is unrelated to any of the predictors.
The \code{"X"} method permutes each predictor matrix, testing the null hypothesis of no relationship, but importantly does not control for any covariance among predictors.
Note that if your formula contains only a single predictor, the function will default to \code{permutation = "Y"}.
}
