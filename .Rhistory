}
#get parameter estimates
if(method == "Whitehead"){
result <- stats::optim(initial.params, fn = LL.whitehead, X = X, D = D, delt = res, hessian = T) #MLE for all AIs
}
if(method == "Beta-binomial"){
result <- stats::optim(initial.params, fn = LL.betabinom, X = X, D = D, hessian = T) #MLE for all AIs
}
#transform parameters
a <- exp(result$par[1])
b <- exp(result$par[2])
#calculate mean and standard deviation
mean.fit <- a/(a+b)
sd.fit <- sqrt((a*b)/((a+b)^2*(a+b+1)))
#estimate of social differentiation
estimate <- sd.fit/mean.fit
#observed CV
observed <- stats::sd(X/D)/mean(X/D)
#estimated correlation
correlation <- estimate/observed
#sample parameters based on estimates and hessian matrix
samp <- MASS::mvrnorm(n = 100000, mu = result$par, Sigma = solve(result$hessian))
#distribution of CVs
cv.samp <- apply(samp,1,function(z){
a <- exp(z[1])
b <- exp(z[2])
mean.fit = a/(a+b)
sd.fit = sqrt((a*b)/((a+b)^2*(a+b+1)))
sd.fit/mean.fit
})
#get SEs and CIs
se_S <- sd(cv.samp, na.rm = T)
se_r <- sd(cv.samp/observed, na.rm = T)
ci_S <- quantile(cv.samp, c(0.025,0.975), na.rm = T)
ci_r <- quantile(cv.samp/observed, c(0.025,0.975), na.rm = T)
#make summary table
summary <- matrix(nrow = 3, ncol = 4)
row.names(summary) <- c("Observed CV","Social Differentiation", "Correlation")
colnames(summary) <- c("Estimate", "SE", "Lower CI", "Upper CI")
summary[1,1] <- observed
summary[2,1] <- estimate
summary[2,2] <- se_S
summary[2,c(3,4)] <- ci_S
summary[3,1] <- correlation
summary[3,2] <- se_r
summary[3,c(3,4)] <- ci_r
return(summary)
}
social_differentiation(X,D,method="Whitehead")
social_differentiation(X,D,method="Beta-binomial")
social_differentiation(X,D,method="Beta-binomial")
social_differentiation(X,D,method="Beta-binomial")
social_differentiation(X,D,method="Beta-binomial")
social_differentiation(X,D,method="Whitehead")
#' Generate Null Distributions for Group-by-Individual Data
#'
#' Produce null distributions of target statistics by permuting a group-by-individual matrix using the MCMC routine proposed by Bejder et al. (1998).
#'
#' @param data A group by individual matrix
#' @param ind_constraint A vector of individual characteristics to constrain permutations; defaults to NULL
#' @param group_constraint A vector group characteristics (usually time windows) to constrain permutations; defaults to NULL
#' @param sample The number of samples to draw for each chain. Defaults to 1000.
#' @param thin The number of steps between each draw. Defaults to 100.
#' @param burnin The number of samples before target statistics are calculated. Defaults to 1000.
#' @param chains The number of independent chains to run. Defaults to 2.
#' @param FUN A function taking a GBI as an input and outputting a vector of any length. See Details.
#'
#' @details For some applications, it may be desirable to compare the observed social structure to a null model in which there are no social preferences. This is particularly useful when investigating whether individuals have social preferences, but may also have other uses.
#' In these cases, the canonical method for generating the null model is a Markov Chain Monte Carlo procedure. For each iteration, a change in the matrix is proposed; if the change maintains row an column totals, and falls within the specified constraints, it is accepted, otherwise the matrix stays at its current state.
#' While this method is widely used in social network analysis, and has been implemented in other software, it is often not implemented properly to generate a valid MCMC chain.
#' In addition, none of the current implementations utilize the toolkit that has been developed to check MCMC chain convergence, or provide confidence intervals for p-values. This implementation fills in these gaps.
#'
#' This function takes an argument FUN, which allows users to define custom test statistics. This argument should be a function taking a single argument (the group by individual matrix) and outputting a vector (the test statistic(s)).
#' By default, this function will calculate the test statistics suggested by Whitehead (2008) for testing for non-random social structure: the mean, SD, CV, and portion non-zero association indices (the SRI by default).
#' Other network statistics can be calculated as well (such as clustering coefficient, modularity, etc.).
#'
#' @return An object of class \code{gbi_null}
#'
#' @export
gbi_null <- function(data,
ind_constraint = NULL,
group_constraint = NULL,
samples = 1000,
thin = 100,
burnin = 1000,
chains = 2,
FUN = NULL){
if(!is.matrix(data) | any(!c(data) %in% c(0,1)) | any(is.na(data))){
stop("Data must be a matrix containing only 1s and 0s")
}
N <- ncol(data)
G <- nrow(data)
if(is.null(group_constraint)) group_constraint <- rep(1,G)
if(is.null(ind_constraint)) ind_constraint <- rep(1,N)
if(!is.vector(group_constraint) | length(group_constraint) != G | any(is.na(group_constraint))) stop("group_constraint must be a vector with length equal to the number of groups")
if(!is.vector(ind_constraint) | length(ind_constraint) != N | any(is.na(ind_constraint))) stop("ind_constraint must be a vector with length equal to the number of individuals")
if(is.null(FUN)){
FUN <- function(gbi){
x <- get_numerator(gbi,data_format="GBI",return="vector")
d <- get_denominator(gbi,data_format="GBI",return="vector")
sri <- x/d
res <- c(mean(sri,na.rm=T),sd(sri,na.rm=T),sd(sri,na.rm=T)/mean(sri,na.rm=T),mean(sri > 0, na.rm=T))
names(res) <- c("Mean","SD","CV","Non-zero")
return(res)
}
}
if(!is.function(FUN)) stop("FUN must be a function")
observed <- FUN(data)
chain_res <- list()
for(k in 1:chains){
gbi.p <- data
res_matrix <- matrix(nrow = samples, ncol = length(observed))
colnames(res_matrix) <- names(observed)
for(i in 1:burnin){
for(j in 1:thin){
cols <- sample(N,2)
rows <- sample(G,2)
trial_matrix <- gbi.p[rows,cols]
if( all(rowSums(trial_matrix) == 1) &
all(colSums(trial_matrix) == 1) &
group_constraint[rows[1]] == group_constraint[rows[2]] &
ind_constraint[cols[1]] == ind_constraint[cols[2]]){
trial_matrix <- ifelse(trial_matrix == 1, 0, 1)
gbi.p[rows,cols] <- trial_matrix
}
}
}
for(i in 1:samples){
for(j in 1:thin){
cols <- sample(N,2)
rows <- sample(G,2)
trial_matrix <- gbi.p[rows,cols]
if( all(rowSums(trial_matrix) == 1) &
all(colSums(trial_matrix) == 1) &
group_constraint[rows[1]] == group_constraint[rows[2]] &
ind_constraint[cols[1]] == ind_constraint[cols[2]]){
trial_matrix <- ifelse(trial_matrix == 1, 0, 1)
gbi.p[rows,cols] <- trial_matrix
}
}
res_matrix[i,] <- FUN(gbi.p)
}
chain_res[[k]] <- coda::mcmc(res_matrix, thin = thin, start = thin, end = thin*samples)
}
chain_res <- coda::mcmc.list(chain_res)
results <- list(
FUN = FUN,
observed = observed,
mcmc = chain_res
)
class(results) <- "gbi_null"
return(results)
}
#' Plot Null Distributions for Group-By-Individual Matrices
#'
#' Diagnostic plots for GBI null hypotheses tested with the Manly-Bejder MCMC procedure
#'
#' @param x A \code{gbi_null} object
#'
#' @details This function will first plot the trace plots for the null distributions of each test statistic. It will then plot the change in estimated p-values over the chains.
plot.gbi_null <- function(x){
plot(x$mcmc)
par(mfrow = c(which.min(c(4,length(x$observed))),1))
for(i in 1:length(x$observed)){
for(k in 1:length(x$mcmc)){
pval_gr <- cumsum(x$mcmc[[k]][,i] > x$observed[i])/(1:length(x$mcmc[[k]][,i]))
if(k == 1){
plot(pval_gr, main = names(x$observed)[i], type = "l", col = k, xlab = "Iteration", ylab = "P(Random > Observed)", ylim = c(0,1))
}else{
points(pval_gr, type = "l", col = k)
}
}
}
}
require(aninet)
test <- gbi_null(srkw_sampling, samples = 100, thin = 10, burnin = 10)
srkw_sampling
test <- gbi_null(srkw_sightings, samples = 100, thin = 10, burnin = 10)
plot(test)
plot(test)
par(mar = c(4,4,1,1))
plot(test)
data <- matrix(rbinom(n = 40*200, size = 1, prob = 0.1) ,nrow = 200, ncol = 40)
test <- gbi_nulldata, samples = 100, thin = 10, burnin = 10)
test <- gbi_null(data, samples = 100, thin = 10, burnin = 10)
plot(test)
test <- gbi_null(data, samples = 1000, thin = 100, burnin = 100, chains = 4)
plot(test)
gbi_MCMC <- function(data,
ind_constraint = NULL,
group_constraint = NULL,
samples = 1000,
thin = 100,
burnin = 1000,
chains = 2,
FUN = NULL){
if(!is.matrix(data) | any(!c(data) %in% c(0,1)) | any(is.na(data))){
stop("Data must be a matrix containing only 1s and 0s")
}
N <- ncol(data)
G <- nrow(data)
if(is.null(group_constraint)) group_constraint <- rep(1,G)
if(is.null(ind_constraint)) ind_constraint <- rep(1,N)
if(!is.vector(group_constraint) | length(group_constraint) != G | any(is.na(group_constraint))) stop("group_constraint must be a vector with length equal to the number of groups")
if(!is.vector(ind_constraint) | length(ind_constraint) != N | any(is.na(ind_constraint))) stop("ind_constraint must be a vector with length equal to the number of individuals")
if(is.null(FUN)){
FUN <- function(gbi){
x <- get_numerator(gbi,data_format="GBI",return="vector")
d <- get_denominator(gbi,data_format="GBI",return="vector")
sri <- x/d
res <- c(mean(sri,na.rm=T),sd(sri,na.rm=T),sd(sri,na.rm=T)/mean(sri,na.rm=T),mean(sri > 0, na.rm=T))
names(res) <- c("Mean","SD","CV","Non-zero")
return(res)
}
}
if(!is.function(FUN)) stop("FUN must be a function")
observed <- FUN(data)
chain_res <- list()
for(k in 1:chains){
gbi.p <- data
res_matrix <- matrix(nrow = samples, ncol = length(observed))
colnames(res_matrix) <- names(observed)
for(i in 1:burnin){
for(j in 1:thin){
cols <- sample(N,2)
rows <- sample(G,2)
trial_matrix <- gbi.p[rows,cols]
if( all(rowSums(trial_matrix) == 1) &
all(colSums(trial_matrix) == 1) &
group_constraint[rows[1]] == group_constraint[rows[2]] &
ind_constraint[cols[1]] == ind_constraint[cols[2]]){
trial_matrix <- ifelse(trial_matrix == 1, 0, 1)
gbi.p[rows,cols] <- trial_matrix
}
}
}
for(i in 1:samples){
for(j in 1:thin){
cols <- sample(N,2)
rows <- sample(G,2)
trial_matrix <- gbi.p[rows,cols]
if( all(rowSums(trial_matrix) == 1) &
all(colSums(trial_matrix) == 1) &
group_constraint[rows[1]] == group_constraint[rows[2]] &
ind_constraint[cols[1]] == ind_constraint[cols[2]]){
trial_matrix <- ifelse(trial_matrix == 1, 0, 1)
gbi.p[rows,cols] <- trial_matrix
}
}
res_matrix[i,] <- FUN(gbi.p)
}
chain_res[[k]] <- coda::mcmc(res_matrix, thin = thin, start = thin, end = thin*samples)
}
chain_res <- coda::mcmc.list(chain_res)
results <- list(
FUN = FUN,
observed = observed,
mcmc = chain_res
)
class(results) <- "gbi_null"
return(results)
}
test <- gbi_null(data, samples = 10000, thin = 100, burnin = 100, chains = 4)
plot(test)
gelman.diag(x$mcmc)
require(coda)
gelman.diag(x$mcmc)
gelman.diag(test$mcmc)
mcmcse::ess(test$mcmc[[1]])
mcmcse::ess(test$mcmc[[2]])
?ess
ess_mean <- mcmcse::ess(test$mcmc)
ess_mean
x <- test
psrf <- coda::gelman.diag(x$mcmc,multivariate = F)
ess_mean <- mcmcse::ess(x$mcmc)
ess_pval <- mcmcse::ess(x$mcmc, g = function(z){
z > x$observed
})
ess_pval <- lapply(x$mcmc, function(y){
mcmcse::ess(y, g = function(z){
z > x$observed
})
})
ess_pval
ess_pval <- lapply(x$mcmc, function(y){
mcmcse::ess(y, g = function(z){
ifelse(z > x$observed,1,0)
})
})
ess_pval
mcmcse::ess(x$mcmc)
mcmcse::ess(x$mcmc[[1]])
mcmcse::ess(x$mcmc[[2]])
mcmcse::ess(x$mcmc[[3]])
plot(ifelse(x$mcmc[[1]][,1] > x$observed[1], 1, 0))
plot(ifelse(x$mcmc[[1]][,1] > x$observed[1], 1, 0), type = "l")
acf(ifelse(x$mcmc[[1]][,1] > x$observed[1], 1, 0))
pval_matrices <- lapply(x$mcmc, function(y){
apply(y, 1, function(z){
ifelse(z > x$observed, 1, 0)
})
})
pval_matrices[[1]]
pval_matrices <- lapply(x$mcmc, function(y){
t(apply(y, 1, function(z){
ifelse(z > x$observed, 1, 0)
}))
})
ess(pval_matrices)
mcmcse::ess(pval_matrices)
pval_matrices[[1]]
pval_matrices <- mcmc.list(lapply(x$mcmc, function(y){
mcmc(t(apply(y, 1, function(z){
ifelse(z > x$observed, 1, 0)
})))
}))
ess(pval_matrices)
require(mcmcse)
ess(pval_matrices)
ess_pval <- mcmcse::ess(pval_matrices)
ess_pval
p_gr <- sapply(length(x$observed), function(z){
mean(all_mcmc[,z] > x$observed[z])
})
all_mcmc <- do.call(rbind, x$mcmc)
p_gr <- sapply(length(x$observed), function(z){
mean(all_mcmc[,z] > x$observed[z])
})
p_ls <- sapply(length(x$observed), function(z){
mean(all_mcmc[,z] < x$observed[z])
})
p_twotail <- sapply(1:length(x$observed), function(z){
min(c(p_gr[z],p_ls[z]))*2
})
p_gr
p_ls
p_twotailed
p_twotail
x$observed
p_gr <- sapply(length(x$observed), function(z){
mean(all_mcmc[,z] > x$observed[z])
})
p_gr
p_gr <- sapply(1:length(x$observed), function(z){
mean(all_mcmc[,z] > x$observed[z])
})
p_ls <- sapply(1:length(x$observed), function(z){
mean(all_mcmc[,z] < x$observed[z])
})
p_twotail <- sapply(1:length(x$observed), function(z){
min(c(p_gr[z],p_ls[z]))*2
})
p_twotail
p_gr
p_ls
require(binom)
ci_gr <- binom.confint(p_gr*ess_pval, ess_pval, method = "exact")
ci_gr
ci_gr <- binom.confint(p_gr*ess_pval, ess_pval, method = "exact")
ci_ls <- binom.confint(p_ls*ess_pval, ess_pval, method = "exact")
ci_tt <- binom.confint(p_twotail*ess_pval, ess_pval, method = "exact")
ci_tt
ci_gr <- binom::binom.confint(p_gr*ess_pval, ess_pval, method = "exact")[,5:6]
ci_ls <- binom::binom.confint(p_ls*ess_pval, ess_pval, method = "exact")[,5:6]
ci_tt <- binom::binom.confint(p_twotail*ess_pval, ess_pval, method = "exact")[,5:6]
ci_gr
upper_summary <- cbind(p_gr,ci_gr)
lower_summary <- cbind(p_ls,ci_ls)
twotail_summary <- cbind(p_twotail,ci_tt)
colnames(upper_summary) <- colnames(lower_summary) <- colnames(twotail_summary) <- c("P-Value","95% UCI","95% LCI")
row.names(upper_summary) <- row.names(lower_summary) <- row.names(twotail_summary) <- names(x$observed)
HPDinterval(x$mcmc)
summary(x$mcmc)
cat("P(Random > Observed)"m"\n")
cat("P(Random > Observed)","\n")
print(upper_summary)
cat("\n")
cat("P(Random > Observed)","\n")
print(upper_summary)
cat("\n")
cat("P(Random < Observed)","\n")
print(lower_summary)
cat("\n")
cat("Two-Tailed P-values","\n")
print(twotail_summary)
cat("\n")
upper_summary <- cbind(p_gr,ci_gr,ess_pval)
lower_summary <- cbind(p_ls,ci_ls,ess_pval)
twotail_summary <- cbind(p_twotail,ci_tt,ess_pval)
colnames(upper_summary) <- colnames(lower_summary) <- colnames(twotail_summary) <- c("P-Value","95% UCI","95% LCI","ESS")
row.names(upper_summary) <- row.names(lower_summary) <- row.names(twotail_summary) <- names(x$observed)
cat("P(Random > Observed)","\n")
print(upper_summary)
cat("\n")
cat("P(Random < Observed)","\n")
print(lower_summary)
cat("\n")
cat("Two-Tailed P-values","\n")
print(twotail_summary)
hpdi <- HPDinterval(all_mcmc)
hpdi <- HPDinterval(as.mcmc(all_mcmc))
hpdi
hpdi <- as.matrix(HPDinterval(as.mcmc(all_mcmc)))
hpdi
attr(hpdi)
attr(hpdi,"Probability")
summary(x$mcmc)
psrf(pval_matrices)
gelman.diag(pval_matrices)
pval_matrices <- coda::mcmc.list(lapply(x$mcmc, function(y){
coda::mcmc(t(apply(y, 1, function(z){
ifelse(z > x$observed, 1, 0)
})))
}))
gelman.diag(pval_matrices)
psrf
null_means <- colMeans(all_mcmc)
null_median <- apply(all_mcmc,2,median)
null_sd <- apply(all_mcmc,2,sd)
hpdi <- coda::HPDinterval(as.mcmc(all_mcmc))
hpdi
cbind(x$observed,null_means,null_median,null_sd,hpdi)
colnames(dist_summary) <- c("Observed", "Random Mean", "Random Median", "Random SD", "Random 95% LCI", "Ranomd 95% UCI")
dist_summary <- cbind(x$observed,null_means,null_median,null_sd,hpdi)
colnames(dist_summary) <- c("Observed", "Random Mean", "Random Median", "Random SD", "Random 95% LCI", "Random 95% UCI")
dist_summary
colnames(dist_summary) <- c("Observed", "Null Mean", "Null Median", "Null SD", "Null 95% LCI", "Null 95% UCI")
dist_summary
hpdi <- apply(all_mcmc,2,quantile,probs=c(0.025,0.975))
CI <- apply(all_mcmc,2,quantile,probs=c(0.025,0.975))
CI
CI <- t(apply(all_mcmc,2,quantile,probs=c(0.025,0.975)))
dist_summary <- cbind(x$observed,null_means,null_median,null_sd,CI)
colnames(dist_summary) <- c("Observed", "Null Mean", "Null Median", "Null SD", "Null 95% LCI", "Null 95% UCI")
dist_summary
summary.gbi_null <- function(x){
psrf <- coda::gelman.diag(x$mcmc,multivariate = F)
ess_mean <- mcmcse::ess(x$mcmc)
null_means <- colMeans(all_mcmc)
null_median <- apply(all_mcmc,2,median)
null_sd <- apply(all_mcmc,2,sd)
CI <- t(apply(all_mcmc,2,quantile,probs=c(0.025,0.975)))
dist_summary <- cbind(x$observed,null_means,null_median,null_sd,CI)
colnames(dist_summary) <- c("Observed", "Null Mean", "Null Median", "Null SD", "Null 95% LCI", "Null 95% UCI")
cat("Null Distribution", "\n")
print(dist_summary)
cat("\n")
pval_matrices <- coda::mcmc.list(lapply(x$mcmc, function(y){
coda::mcmc(t(apply(y, 1, function(z){
ifelse(z > x$observed, 1, 0)
})))
}))
ess_pval <- mcmcse::ess(pval_matrices)
all_mcmc <- do.call(rbind, x$mcmc)
p_gr <- sapply(1:length(x$observed), function(z){
mean(all_mcmc[,z] > x$observed[z])
})
p_ls <- sapply(1:length(x$observed), function(z){
mean(all_mcmc[,z] < x$observed[z])
})
p_twotail <- sapply(1:length(x$observed), function(z){
min(c(p_gr[z],p_ls[z]))*2
})
ci_gr <- binom::binom.confint(p_gr*ess_pval, ess_pval, method = "exact")[,5:6]
ci_ls <- binom::binom.confint(p_ls*ess_pval, ess_pval, method = "exact")[,5:6]
ci_tt <- binom::binom.confint(p_twotail*ess_pval, ess_pval, method = "exact")[,5:6]
upper_summary <- cbind(p_gr,ci_gr,ess_pval)
lower_summary <- cbind(p_ls,ci_ls,ess_pval)
twotail_summary <- cbind(p_twotail,ci_tt,ess_pval)
colnames(upper_summary) <- colnames(lower_summary) <- colnames(twotail_summary) <- c("P-Value","95% UCI","95% LCI","ESS")
row.names(upper_summary) <- row.names(lower_summary) <- row.names(twotail_summary) <- names(x$observed)
cat("P(Random > Observed)","\n")
print(upper_summary)
cat("\n")
cat("P(Random < Observed)","\n")
print(lower_summary)
cat("\n")
cat("Two-Tailed P-values","\n")
print(twotail_summary)
cat("\n")
}
summary(test)
dist_summary <- cbind(x$observed,null_means,null_median,null_sd,CI,ess_mean,psrf)
colnames(dist_summary) <- c("Observed", "Null Mean", "Null Median", "Null SD", "Null 95% LCI", "Null 95% UCI","ESS","PSRF")
cat("Null Distribution", "\n")
print(dist_summary)
psrf <- coda::gelman.diag(x$mcmc,multivariate = F)
psrf
psrf <- coda::gelman.diag(x$mcmc,multivariate = F)[,1]
psrf <- coda::gelman.diag(x$mcmc,multivariate = F)[[1]][,1]
psrf
ess_mean <- mcmcse::ess(x$mcmc)
null_means <- colMeans(all_mcmc)
null_median <- apply(all_mcmc,2,median)
null_sd <- apply(all_mcmc,2,sd)
CI <- t(apply(all_mcmc,2,quantile,probs=c(0.025,0.975)))
dist_summary <- cbind(x$observed,null_means,null_median,null_sd,CI,ess_mean,psrf)
colnames(dist_summary) <- c("Observed", "Null Mean", "Null Median", "Null SD", "Null 95% LCI", "Null 95% UCI","ESS","PSRF")
cat("Null Distribution", "\n")
print(dist_summary)
cat("\n")
dist_summary <- cbind(null_means,null_median,null_sd,CI,ess_mean,psrf)
colnames(dist_summary) <- c("Mean", "Median", "SD", "95% LCI", "95% UCI","ESS","PSRF")
cat("Null Distribution", "\n")
print(dist_summary)
library(aninet)
?gbi_MCMC
library(aninet)
library(aninet)
library(aninet)
aninet::gbi_MCMC(aninet::srkw_sightings)
