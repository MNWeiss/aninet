t.perm <- matrix(nrow = nperm, ncol = ncol(X)) #matrix to hold t values
for(j in 1:ncol(X)){
x <- X[,j] #get the jth predictor
z <- X[,-j] #get all other predictors
resid.x <- residuals(lm(x ~ -1 + z)) #get residuals
for(i in 1:nperm){ #for each permutation
for(k in 1:length(all_groups)){ # for each unique group
resid.x[group.memb == all_groups[k]] <- sample(resid.x[group.memb == all_groups[k]]) #shuffle the residuals in that group
}
data.perm <- data #copy original data
data.perm[,fixed[j]] <- resid.x #plug in residuals
if(fixed[j] == "(Intercept)"){ # if testing the intercept
colnames(data.perm)[colnames(data.perm) == fixed[j]] <- "Intercept" # get a nicer intercept
form.j <- update(form, ~ . + Intercept - 1) # update the formula
fit.perm <- lme4::lmer(form.j, data = data.perm) # fit the permuted model
t.perm[i,j] <- summary(fit.perm)$coef["Intercept",3] #save t-value
}else{
fit.perm <- lme4::lmer(form, data = data.perm) # fit the permuted model
t.perm[i,j] <- summary(fit.perm)$coef[j,3] # save the t-value
}
}
}
t.obs <- summary(model)$coef[,3] #observed t-value
# calculate p-values
pval <- sapply(1:length(t.obs), function(z){
p.gr <- mean(c(t.perm[,z],t.obs[z]) >= t.obs[z])
p.ls <- mean(c(t.perm[,z],t.obs[z]) <= t.obs[z])
min(c(p.gr,p.ls))*2
})
# make a summary table
summary_table <- summary(model)$coef
summary_table <- cbind(summary_table, pval)
colnames(summary_table)[4] <- "P-value"
# return the summary table
return(summary_table)
}
dsp.glmer <- function(model, nperm){
fam <- family(model)
form <- formula(model) # get the formula from the model
if(grepl("*",as.character(form)[[3]], fixed = T) | grepl(":",as.character(form)[[3]], fixed = T)){
stop("Model contains interaction effects; DSP cannot test these models")
}
data <- model@frame # get the data from the model
data <- cbind(data,rep(1,nrow(data))) # add an intercept column
colnames(data)[ncol(data)] <- "(Intercept)" # name the intercept column
fixed <- names(fixef(model)) #get the names of the fixed effects
rand <- names(ranef(model)) #names of the random effects
X <- data[,fixed,drop=F] # get the fixed predictors as a matrix
if(any(apply(X,2,class) == "factor")) stop("Fixed predictors must be numeric")
X <- as.matrix(X) # make the predictors a matrix
B <- data[,rand,drop=F] #get the random effect matrix
group.memb <- apply(B,1,function(z){
paste(z,collapse="-") # collapse all group memberships into a single character vector
})
all_groups <- unique(group.memb) # unique group memberships
if(length(all_groups) == nrow(data)){
stop("Number of unique random effect levels equal to number of observations")
}
Y <- data[,!colnames(data) %in% c(rand,fixed)] #get the responses
t.perm <- matrix(nrow = nperm, ncol = ncol(X)) #matrix to hold t values
for(j in 1:ncol(X)){
x <- X[,j] #get the jth predictor
z <- X[,-j] #get all other predictors
resid.x <- residuals(lm(x ~ -1 + z)) #get residuals
for(i in 1:nperm){ #for each permutation
for(k in 1:length(all_groups)){ # for each unique group
resid.x[group.memb == all_groups[k]] <- sample(resid.x[group.memb == all_groups[k]]) #shuffle the residuals in that group
}
data.perm <- data #copy original data
data.perm[,fixed[j]] <- resid.x #plug in residuals
if(fixed[j] == "(Intercept)"){ # if testing the intercept
colnames(data.perm)[colnames(data.perm) == fixed[j]] <- "Intercept" # get a nicer intercept
form.j <- update(form, ~ . + Intercept - 1) # update the formula
fit.perm <- lme4::glmer(form.j, data = data.perm, family = fam) # fit the permuted model
t.perm[i,j] <- summary(fit.perm)$coef["Intercept",3] #save t-value
}else{
fit.perm <- lme4::glmer(form, data = data.perm, family = fam) # fit the permuted model
t.perm[i,j] <- summary(fit.perm)$coef[j,3] # save the t-value
}
}
}
t.obs <- summary(model)$coef[,3] #observed t-value
# calculate p-values
pval <- sapply(1:length(t.obs), function(z){
p.gr <- mean(c(t.perm[,z],t.obs[z]) >= t.obs[z])
p.ls <- mean(c(t.perm[,z],t.obs[z]) <= t.obs[z])
min(c(p.gr,p.ls))*2
})
# make a summary table
summary_table <- summary(model)$coef
summary_table[,4] <- pval
colnames(summary_table)[4] <- "P-value"
# return the summary table
return(summary_table)
}
dsp.lm <- function(model, nperm){
form <- formula(model) # get the formula from the model
if(grepl("*",as.character(form)[[3]], fixed = T) | grepl(":",as.character(form)[[3]], fixed = T)){
stop("Model contains interaction effects; DSP cannot test these models")
}
data <- model.frame(model)
data <- cbind(data,rep(1,nrow(data))) # add an intercept column
colnames(data)[ncol(data)] <- "(Intercept)" # name the intercept column
fixed <- names(coef(model)) #get the names of the fixed effects
X <- data[,fixed,drop=F] # get the fixed predictors as a matrix
if(any(apply(X,2,class) == "factor")) stop("Fixed predictors must be numeric")
X <- as.matrix(X) # make the predictors a matrix
Y <- data[,!colnames(data) %in% fixed] #get the responses
t.perm <- matrix(nrow = nperm, ncol = ncol(X)) #matrix to hold t values
for(j in 1:ncol(X)){
x <- X[,j] #get the jth predictor
z <- X[,-j] #get all other predictors
resid.x <- residuals(lm(x ~ -1 + z)) #get residuals
for(i in 1:nperm){ #for each permutation
resid.x <- sample(resid.x) #shuffle the residuals in that group
data.perm <- data #copy original data
data.perm[,fixed[j]] <- resid.x #plug in residuals
if(fixed[j] == "(Intercept)"){ # if testing the intercept
colnames(data.perm)[colnames(data.perm) == fixed[j]] <- "Intercept" # get a nicer intercept
form.j <- update(form, ~ . + Intercept - 1) # update the formula
fit.perm <- lm(form.j, data = data.perm) # fit the permuted model
t.perm[i,j] <- summary(fit.perm)$coef["Intercept",3] #save t-value
}else{
fit.perm <- lm(form, data = data.perm) # fit the permuted model
t.perm[i,j] <- summary(fit.perm)$coef[j,3] # save the t-value
}
}
}
t.obs <- summary(model)$coef[,3] #observed t-value
# calculate p-values
pval <- sapply(1:length(t.obs), function(z){
p.gr <- mean(c(t.perm[,z],t.obs[z]) >= t.obs[z])
p.ls <- mean(c(t.perm[,z],t.obs[z]) <= t.obs[z])
min(c(p.gr,p.ls))*2
})
# make a summary table
summary_table <- summary(model)$coef
summary_table[,4] <- pval
colnames(summary_table)[4] <- "P-value"
# return the summary table
return(summary_table)
}
dsp.glm <- function(model, nperm){
form <- formula(model) # get the formula from the model
if(grepl("*",as.character(form)[[3]], fixed = T) | grepl(":",as.character(form)[[3]], fixed = T)){
stop("Model contains interaction effects; DSP cannot test these models")
}
data <- model.frame(model)
data <- cbind(data,rep(1,nrow(data))) # add an intercept column
colnames(data)[ncol(data)] <- "(Intercept)" # name the intercept column
fixed <- names(coef(model)) #get the names of the fixed effects
X <- data[,fixed,drop=F] # get the fixed predictors as a matrix
if(any(apply(X,2,class) == "factor")) stop("Fixed predictors must be numeric")
X <- as.matrix(X) # make the predictors a matrix
Y <- data[,!colnames(data) %in% fixed] #get the responses
t.perm <- matrix(nrow = nperm, ncol = ncol(X)) #matrix to hold t values
for(j in 1:ncol(X)){
x <- X[,j] #get the jth predictor
z <- X[,-j] #get all other predictors
resid.x <- residuals(lm(x ~ -1 + z)) #get residuals
for(i in 1:nperm){ #for each permutation
resid.x <- sample(resid.x) #shuffle the residuals in that group
data.perm <- data #copy original data
data.perm[,fixed[j]] <- resid.x #plug in residuals
if(fixed[j] == "(Intercept)"){ # if testing the intercept
colnames(data.perm)[colnames(data.perm) == fixed[j]] <- "Intercept" # get a nicer intercept
form.j <- update(form, ~ . + Intercept - 1) # update the formula
fit.perm <- lm(form.j, data = data.perm) # fit the permuted model
t.perm[i,j] <- summary(fit.perm)$coef["Intercept",3] #save t-value
}else{
fit.perm <- lm(form, data = data.perm) # fit the permuted model
t.perm[i,j] <- summary(fit.perm)$coef[j,3] # save the t-value
}
}
}
t.obs <- summary(model)$coef[,3] #observed t-value
# calculate p-values
pval <- sapply(1:length(t.obs), function(z){
p.gr <- mean(c(t.perm[,z],t.obs[z]) >= t.obs[z])
p.ls <- mean(c(t.perm[,z],t.obs[z]) <= t.obs[z])
min(c(p.gr,p.ls))*2
})
# make a summary table
summary_table <- summary(model)$coef
summary_table[,4] <- pval
colnames(summary_table)[4] <- "P-value"
# return the summary table
return(summary_table)
}
model_eigen <- lme4::lmer(log(contact_eigen) ~ age + sex, data = srkw_attributes)
model_eigen <- lme4::lmer(log(contact_eigen) ~ age + sex + (1|matriline), data = srkw_attributes)
double_semi_partialling(model_eigen, 1000)
contact_eigen
suppressWarnings(double_semi_partialling(model_eigen, 1000))
model_eigen <- lm(log(contact_eigen) ~ age + sex, data = srkw_attributes)
model_eigen <- lm(log(contact_eigen) ~ age + sex, data = srkw_attributes)
double_semi_partialling(model_eigen, 1000)
library(aninet)
?double_semi_partialling
library(aninet)
m1 <- latent_space(srkw_contact ~ 1, ind.RE = F)
m1 <- latent_space(srkw_contact ~ 1, ind.RE = F, effort = srkw_sampling)
plot(m1)
plot(m1)
plot(m1, post.method = "median")
plot(m1, post.method = "mean")
plot(m1, post.method = "mds")
plot(m1, post.method = "mds")
m1 <- latent_space(srkw_contact ~ 1, ind.RE = F, effort = srkw_sampling, adapt = 5000)
plot(m1, post.method = "mds")
plot(m1, post.method = "median")
plot(m1, post.method = "median")
plot(m1, post.method = "mean")
plot(m1, post.method = "median")
plot(m1, post.method = "mds")
library(aninet)
getwd()
library(aninet)
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "~/.Renviron")
Sys.which("make")
Sys.which("make")
library(aninet)
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "/.Renviron")
Sys.which("make")
library(aninet)
require(brms)
?brms::me
View(brms::me)
?deparse
?deparse_combine
View(deparse_combine)
View(brms::deparse_combine)
?substituteDirect
?substitute
View(brms::brm())
View(brms::brm)
?devtools::install_github
?library
library(aninet)
?srkw_sampling
?srkw_contact
?srkw_surfacing
srkw_surfacing
plot(network(srkw_surfacing))
require(network)
plot(network(srkw_surfacing))
plot(network(srkw_surfacing, directed = F))
plot(network(srkw_contact, directed = F))
plot(network(srkw_sampling, directed = F))
plot(network(srkw_contact, directed = F))
plot(network(srkw_contact, directed = F), edge.lwd = srkw_contact)
plot(network(srkw_contact, directed = F), edge.lwd = srkw_contact/srkw_sampling)
plot(network(srkw_contact, directed = F), edge.lwd = (srkw_contact/srkw_sampling)*100)
plot(network(srkw_contact, directed = F), edge.lwd = (srkw_contact/srkw_sampling)*1000)
plot(network(srkw_contact, directed = F), edge.lwd = (srkw_contact/srkw_sampling)*10000)
plot(network(srkw_contact, directed = F), edge.lwd = (srkw_contact/srkw_sampling)*5000)
?integrate
?dbinom
D <- sample(20,20)
D <- sample(20,20,rep=T)
D
X <- rbinom(20,D,prob=rbeta(20,5,5))
X
int_func <- function(p){
prod(dbinom(X,D,p))*dbeta(p,a,b)
}
a <- 1
b <- 2
integrate(int_func, 0, 1)
integrate(int_func, 0, 1, abs.tol = 0)
integrate(int_func, 0, 1, abs.tol = 0)$vale
integrate(int_func, 0, 1, abs.tol = 0)$value
a
b
integrate(int_func, 5, 5, abs.tol = 0)$value
b <- 5
a <- 5
integrate(int_func, 5, 5, abs.tol = 0)$value
integrate(int_func, 0, 1, abs.tol = 0)$value
#likelihood functions for social differentiation
LL.whitehead <- function(z, X, D, delt){
a <- exp(z[1])
b <- exp(z[2])
N <- length(X)
ll_all <- log(sapply(1:N, function(z){
x <- X[z]
d <- d[z]
int_func <- function(p){
dbinom(x,d,p)*dbeta(p,a,b)
}
integrate(int_func,0,1)
}))
-sum(ll_all)
}
optim(LL.whitehead)
optim(c(0,0,),LL.whitehead)
optim(c(0,0),LL.whitehead)
X
D
optim(c(0,0),LL.whitehead,X=X,D=D)
#likelihood functions for social differentiation
LL.whitehead <- function(z, X, D, delt){
a <- exp(z[1])
b <- exp(z[2])
N <- length(X)
ll_all <- log(sapply(1:N, function(z){
x <- X[z]
d <- D[z]
int_func <- function(p){
dbinom(x,d,p)*dbeta(p,a,b)
}
integrate(int_func,0,1)
}))
-sum(ll_all)
}
optim(c(0,0),LL.whitehead,X=X,D=D)
X
D
z <- c(0,0)
a <- exp(z[1])
b <- exp(z[2])
N <- length(X)
ll_all <- log(sapply(1:N, function(z){
x <- X[z]
d <- D[z]
int_func <- function(p){
dbinom(x,d,p)*dbeta(p,a,b)
}
integrate(int_func,0,1)
}))
z <- 1
#likelihood functions for social differentiation
LL.whitehead <- function(z, X, D, delt){
a <- exp(z[1])
b <- exp(z[2])
N <- length(X)
ll_all <- log(sapply(1:N, function(k){
x <- X[k]
d <- D[k]
int_func <- function(p){
dbinom(x,d,p)*dbeta(p,a,b)
}
integrate(int_func,0,1)
}))
-sum(ll_all)
}
optim(c(0,0),LL.whitehead,X=X,D=D)
a <- exp(z[1])
b <- exp(z[2])
N <- length(X)
N
sapply(1:N, function(k){
x <- X[k]
d <- D[k]
int_func <- function(p){
dbinom(x,d,p)*dbeta(p,a,b)
}
integrate(int_func,0,1)
})
int_func
?int_func
?integrate
#likelihood functions for social differentiation
LL.whitehead <- function(z, X, D, delt){
a <- exp(z[1])
b <- exp(z[2])
N <- length(X)
int_func <- function(p,x,d){
dbinom(x,d,p)*dbeta(p,a,b)
}
ll_all <- log(sapply(1:N, function(k){
integrate(int_func,0,1,x=X[k],d=D[k])
}))
-sum(ll_all)
}
optim(c(0,0),LL.whitehead,X=X,D=D)
a <- exp(z[1])
b <- exp(z[2])
N <- length(X)
N
a
b
z[2]
z <- c(0,0)
a <- exp(z[1])
b <- exp(z[2])
N <- length(X)
int_func <- function(p,x,d){
dbinom(x,d,p)*dbeta(p,a,b)
}
ll_all <- log(sapply(1:N, function(k){
integrate(int_func,0,1,x=X[k],d=D[k])
}))
k <- 1
integrate(int_func,0,1,x=X[k],d=D[k])
#likelihood functions for social differentiation
LL.whitehead <- function(z, X, D, delt){
a <- exp(z[1])
b <- exp(z[2])
N <- length(X)
int_func <- function(p,x,d){
dbinom(x,d,p)*dbeta(p,a,b)
}
ll_all <- log(sapply(1:N, function(k){
integrate(int_func,0,1,x=X[k],d=D[k])$val
}))
-sum(ll_all)
}
#likelihood functions for social differentiation
LL.whitehead <- function(z, X, D, delt){
a <- exp(z[1])
b <- exp(z[2])
N <- length(X)
int_func <- function(p,x,d){
dbinom(x,d,p)*dbeta(p,a,b)
}
ll_all <- log(sapply(1:N, function(k){
integrate(int_func,0,1,x=X[k],d=D[k],abs.tol=0)$val
}))
-sum(ll_all)
}
optim(c(0,0),LL.whitehead,X=X,D=D)
optim(c(0,0),LL.whitehead,X=X,D=D)$par
exp(optim(c(0,0),LL.whitehead,X=X,D=D)$par)
#' This function calculates and returns the standard error and confidence interval for the estimated social differentiation and correlation. This is based on the inverse Hessian matrix from the optimization routine. Note that a bootstrap of the raw data may be more robust.
#'
#' @return A matrix containing the estimated social differentiation, the CV of the observed associations, and the estimated correlation between true and observed association indices, along with standard errors and confidence intervals.
#'
#' @examples
#' X <- get_numerator(srkw_sightings, return = "vector", data_format = "GBI")
#' D <- get_denominator(srkw_sightings, return = "vector", data_format = "GBI")
#' social_differentiation(X, D, method = "Beta-binomial")
#'
#' @export
social_differentiation <- function(Num, Den, method = c("Whitehead","Beta-binomial"), res = 0.001,  initial.params = c(0.1,0.1)){
if(length(method) > 1) method <- method[1]
if(!method %in% c("Whitehead","Beta-binomial")) method <- "Whitehead"
X <- Num
D <- Den
#likelihood functions for social differentiation
LL.whitehead <- function(z, X, D, delt){
a <- exp(z[1])
b <- exp(z[2])
N <- length(X)
int_func <- function(p,x,d){
dbinom(x,d,p)*dbeta(p,a,b)
}
ll_all <- log(sapply(1:N, function(k){
integrate(int_func,0,1,x=X[k],d=D[k],abs.tol=0)$val
}))
-sum(ll_all)
}
LL.betabinom <- function(z, X, D){
a <- exp(z[1])
b <- exp(z[2])
ll <- VGAM::dbetabinom.ab(X, size = D, shape1 = a, shape2 = b, log = T)
I <- sum(ll)
-I
}
#get parameter estimates
if(method == "Whitehead"){
result <- stats::optim(initial.params, fn = LL.whitehead, X = X, D = D, delt = res, hessian = T) #MLE for all AIs
}
if(method == "Beta-binomial"){
result <- stats::optim(initial.params, fn = LL.betabinom, X = X, D = D, hessian = T) #MLE for all AIs
}
#transform parameters
a <- exp(result$par[1])
b <- exp(result$par[2])
#calculate mean and standard deviation
mean.fit <- a/(a+b)
sd.fit <- sqrt((a*b)/((a+b)^2*(a+b+1)))
#estimate of social differentiation
estimate <- sd.fit/mean.fit
#observed CV
observed <- stats::sd(X/D)/mean(X/D)
#estimated correlation
correlation <- estimate/observed
#sample parameters based on estimates and hessian matrix
samp <- MASS::mvrnorm(n = 100000, mu = result$par, Sigma = solve(result$hessian))
#distribution of CVs
cv.samp <- apply(samp,1,function(z){
a <- exp(z[1])
b <- exp(z[2])
mean.fit = a/(a+b)
sd.fit = sqrt((a*b)/((a+b)^2*(a+b+1)))
sd.fit/mean.fit
})
#get SEs and CIs
se_S <- sd(cv.samp, na.rm = T)
se_r <- sd(cv.samp/observed, na.rm = T)
ci_S <- quantile(cv.samp, c(0.025,0.975), na.rm = T)
ci_r <- quantile(cv.samp/observed, c(0.025,0.975), na.rm = T)
#make summary table
summary <- matrix(nrow = 3, ncol = 4)
row.names(summary) <- c("Observed CV","Social Differentiation", "Correlation")
colnames(summary) <- c("Estimate", "SE", "Lower CI", "Upper CI")
summary[1,1] <- observed
summary[2,1] <- estimate
summary[2,2] <- se_S
summary[2,c(3,4)] <- ci_S
summary[3,1] <- correlation
summary[3,2] <- se_r
summary[3,c(3,4)] <- ci_r
return(summary)
}
social_differentiation(X,D,method="Whitehead")
social_differentiation(X,D,method="Beta-binomial")
social_differentiation(X,D,method="Beta-binomial")
social_differentiation(X,D,method="Beta-binomial")
social_differentiation(X,D,method="Beta-binomial")
social_differentiation(X,D,method="Whitehead")
