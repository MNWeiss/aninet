<<<<<<< HEAD
require(aninet)
require(asnipe)
require(ergm)
require(ergm.count)
require(latentnet)
require(vegan)
contact_rate <- srkw_contact/srkw_sampling #rate of physical contacts
srkw_strength <- colSums(contact_rate) #individual strength centrality
srkw_strength <- as.numeric(scale(srkw_strength)) # scale the strengths to have mean 0 and SD 1
m1 <- lm(srkw_strength ~ age, data = srkw_attributes) # fit the linear model
strength_t <- summary(m1)$coefficients[2,3] #save the t-value
t_perm <- NA
for(i in 1:1000){
strength_perm <- sample(srkw_strength) #randomize the strength
m1.perm <- lm(strength_perm ~ age, data = srkw_attributes)
t_perm[i] <- summary(m1.perm)$coefficients[2,3]
}
hist(t_perm,col="black",breaks=50,main="",xlab="t-value") #plot the results
abline(v = strength_t, col = "red", lwd = 2)
all_t <- c(strength_t,t_perm) # all t-values
ls <- mean(all_t <= strength_t) # probability of a value less than the observed
gr <- mean(all_t >= strength_t) # probability of a value greater than the observed
pval <- min(c(ls,gr))*2 # two-tailed p-value
pval
contact_mantel <- mantel(contact_rate, srkw_kinship, method = "spearman")
mantel(contact_rate, srkw_kinship, method = "spearman")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
require(aninet)
require(asnipe)
require(ergm)
require(ergm.count)
require(latentnet)
require(vegan)
contact_rate <- srkw_contact/srkw_sampling #rate of physical contacts
srkw_strength <- colSums(contact_rate) #individual strength centrality
srkw_strength <- as.numeric(scale(srkw_strength)) # scale the strengths to have mean 0 and SD 1
m1 <- lm(srkw_strength ~ age, data = srkw_attributes) # fit the linear model
strength_t <- summary(m1)$coefficients[2,3] #save the t-value
t_perm <- NA
for(i in 1:1000){
strength_perm <- sample(srkw_strength) #randomize the strength
m1.perm <- lm(strength_perm ~ age, data = srkw_attributes)
t_perm[i] <- summary(m1.perm)$coefficients[2,3]
}
hist(t_perm,col="black",breaks=50,main="",xlab="t-value") #plot the results
abline(v = strength_t, col = "red", lwd = 2)
all_t <- c(strength_t,t_perm) # all t-values
ls <- mean(all_t <= strength_t) # probability of a value less than the observed
gr <- mean(all_t >= strength_t) # probability of a value greater than the observed
pval <- min(c(ls,gr))*2 # two-tailed p-value
pval
mantel(contact_rate, srkw_kinship, method = "spearman")
age_sim <- attribute_similarity(srkw_attributes$age, type = "abs.diff")
age_sim
?attribute_similarity
age_sim <- attribute_similarity(srkw_attributes$age, type = "absdiff")
age_diff <- attribute_similarity(srkw_attributes$age, type = "absdiff")
age_diff
age_diff <- attribute_similarity(srkw_attributes$age, type = "discrete")
age_diff
age_diff <- attribute_similarity(srkw_attributes$age, type = "absdiff")
age_diff
class(attributes$age)
class(srkw_attributes$age)
library(aninet)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
age_diff <- attribute_similarity(srkw_attributes$age, type = "absdiff")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
require(aninet)
require(asnipe)
require(ergm)
require(ergm.count)
require(latentnet)
require(vegan)
contact_rate <- srkw_contact/srkw_sampling #rate of physical contacts
srkw_strength <- colSums(contact_rate) #individual strength centrality
srkw_strength <- as.numeric(scale(srkw_strength)) # scale the strengths to have mean 0 and SD 1
m1 <- lm(srkw_strength ~ age, data = srkw_attributes) # fit the linear model
strength_t <- summary(m1)$coefficients[2,3] #save the t-value
t_perm <- NA
for(i in 1:1000){
strength_perm <- sample(srkw_strength) #randomize the strength
m1.perm <- lm(strength_perm ~ age, data = srkw_attributes)
t_perm[i] <- summary(m1.perm)$coefficients[2,3]
}
hist(t_perm,col="black",breaks=50,main="",xlab="t-value") #plot the results
abline(v = strength_t, col = "red", lwd = 2)
all_t <- c(strength_t,t_perm) # all t-values
ls <- mean(all_t <= strength_t) # probability of a value less than the observed
gr <- mean(all_t >= strength_t) # probability of a value greater than the observed
pval <- min(c(ls,gr))*2 # two-tailed p-value
pval
mantel(contact_rate, srkw_kinship, method = "spearman")
age_diff <- attribute_similarity(srkw_attributes$age, type = "absdiff")
age_diff
age_sim <- attribute_similarity(srkw_attributes$age, type = "absdiff")
sex_sim <- attribute_similarity(srkw_attributes$sex, type = "discrete")
sex_sim
mrqap.dsp(contact_rate ~ srkw_kinship + age_sim + sex_sim, test.statistic = "t-value")
glmqap(srkw_contact ~ srkw_kinship + age_sim + sex_sim,
offset = log(srkw_sampling),
family = "poisson")
t_perm <- replicate(1000,{
strength_perm <- sample(srkw_strength)
m1.perm <- lm(strength_perm ~ age, data = srkw_attributes)
summary(m1.perm)$coefficients[2,3]
})
hist(t_perm,col="black",breaks=50,main="",xlab="t-value") #plot the results
abline(v = strength_t, col = "red", lwd = 2)
require(aninet)
require(asnipe)
require(ergm)
require(ergm.count)
require(latentnet)
require(vegan)
set.seed(420)
glmqap(srkw_contact ~ srkw_kinship + age_sim + sex_sim,
offset = log(srkw_sampling),
family = "poisson")
glmqap(srkw_contact ~ srkw_kinship + age_sim + sex_sim,
offset = log(srkw_sampling),
family = "poisson")
glmqap(srkw_contact ~ srkw_kinship + age_sim + sex_sim,
offset = log(srkw_sampling),
family = "poisson")
glmqap(srkw_contact ~ srkw_kinship + age_sim + sex_sim,
offset = log(srkw_sampling),
family = "poisson")
ls_contact <- latent_space(srkw_contact ~ srkw_kinship + age_sim + sex_sim,
ind.RE = T, dimensions = 2, effort = srkw_sampling,
family = "poisson")
ls_contact$summary
ls_contact$summary
z.mean <- apply(z, c(1,2), mean)
z <- ls_contact$z
z.mean <- apply(z, c(1,2), mean)
dim(z.mean)
z.mean <- apply(z, c(2,3), mean)
dim(z.mean)
z.mean
contact_network <- network(contact_rate, directed = F, ignore.eval = F, names.eval = "weight")
contact_network
plot(contact_network, coord = z.mean)
plot(contact_network, coord = z.mean)
plot(contact_network, coord = z.mean, edge.lwd = contact_rate/max(contact_rate))
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*200)
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*100)
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*50)
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*10)
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1)
hist(z[,1,2])
hist(z[,1,3])
hist(z[,2,2])
hist(z[,3,2])
hist(z[,4,2])
hist(z[,5,2])
hist(z[,6,2])
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2)
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 3)
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2.5)
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2)
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2)
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2)
ls_contact <- latent_space(srkw_contact ~ srkw_kinship + age_sim + sex_sim,
ind.RE = T, dimensions = 2, effort = srkw_sampling,
family = "poisson", adapt = 1000, burnin = 2000, sample = 2000)
ls_contact$summary
z <- ls_contact$z
z.mean <- apply(z, c(2,3), mean)
contact_network <- network(contact_rate, directed = F, ignore.eval = F, names.eval = "weight")
z <- ls_contact$z
z.mean <- apply(z, c(2,3), mean)
contact_network <- network(contact_rate, directed = F, ignore.eval = F, names.eval = "weight")
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2)
z <- ls_contact$z
z.mean <- apply(z, c(2,3), mean)
contact_network <- network(contact_rate, directed = F, ignore.eval = F, names.eval = "weight")
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2)
avg_d <- apply(ls_contact$distances,c(2,3),mean)
plot(cmdscale(avg_d))
plot(z.mean)
plot(z.mean, xlim = c(-3,3), ylim = c(-3,3))
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2)
z <- ls_contact$z
z.mean <- apply(z, c(2,3), mean)
contact_network <- network(contact_rate, directed = F, ignore.eval = F, names.eval = "weight")
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2)
plot(z.mean, xlim = c(-3,3), ylim = c(-3,3))
z <- ls_contact$z
z.mean <- apply(z, c(2,3), mean)
contact_network <- network(contact_rate, directed = F, ignore.eval = F, names.eval = "weight")
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2, edge.col = rgb(0,0,0,contact_rate/max(contact_rate)))
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2, edge.col = rgb(0,0,0,contact_rate/max(contact_rate)))
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2, edge.col = rgb(0,0,0,contact_rate/max(contact_rate)) + 0.5)
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2, edge.col = rgb(0,0,0,contact_rate/max(contact_rate)))
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2, edge.col = rgb(0,0,0,1-contact_rate/max(contact_rate)))
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2, edge.col = rgb(0,0,0,(1-contact_rate/max(contact_rate))))
contact_network%e%weight
contact_network%e%"weight"
contact_network%e%"col" <- contact_network%e%"weight" - min(contact_network%e%"weight")
coontact_network%e%"col" <- contact_network%e%"col"/max(contact_network%e%"col")
contact_network%e%"col" <- contact_network%e%"col"/max(contact_network%e%"col")
contact_network%e%"col"
hist(contact_network%e%"col")
contact_network%e%"col" <- rgb(0,0,0,contact_network%e%"col")
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2, edge.col = "col")
contact_network <- network(contact_rate, directed = F, ignore.eval = F, names.eval = "weight")
contact_network%e%"col" <- contact_network%e%"weight" - min(contact_network%e%"weight" + 0.001)
contact_network%e%"col" <- rgb(0,0,0,contact_network%e%"col")
contact_network <- network(contact_rate, directed = F, ignore.eval = F, names.eval = "weight")
contact_network%e%"col" <- contact_network%e%"weight" - min(contact_network%e%"weight") + 0.001
contact_network%e%"col" <- contact_network%e%"col"/max(contact_network%e%"col")
contact_network%e%"col" <- rgb(0,0,0,contact_network%e%"col")
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2, edge.col = "col")
contact_network%e%"col" <- contact_network%e%"weight" - min(contact_network%e%"weight") + 0.01
contact_network%e%"col" <- rgb(0,0,0,contact_network%e%"col")
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2, edge.col = "col")
contact_network%e%"col" <- contact_network%e%"weight" - min(contact_network%e%"weight") + 0.001
contact_network%e%"col" <- rgb(0,0,0,contact_network%e%"col")
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2, edge.col = "col")
contact_network%e%"col" <- contact_network%e%"weight" - min(contact_network%e%"weight") + 0.001
contact_network%e%"col" <- rgb(0,0,0,1-contact_network%e%"col")
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2, edge.col = "col")
contact_network <- network(contact_rate, directed = F, ignore.eval = F, names.eval = "weight")
contact_network%e%"col" <- contact_network%e%"weight" - min(contact_network%e%"weight") + 0.001
contact_network%e%"col"
hist(contact_network%e%"col")
contact_network%e%"col" <- contact_network%e%"col"/max(contact_network%e%"col")
hist(contact_network%e%"col")
contact_network%e%"col" <- contact_network%e%"weight" - min(contact_network%e%"weight") + 0.0001
contact_network%e%"col" <- contact_network%e%"col"/max(contact_network%e%"col")
contact_network%e%"col" <- rgb(0,0,0,1-contact_network%e%"col")
hist(contact_network%e%"col")
contact_network <- network(contact_rate, directed = F, ignore.eval = F, names.eval = "weight")
contact_network%e%"col" <- contact_network%e%"col"/max(contact_network%e%"col")
hist(contact_network%e%"col")
hist(contact_network%e%"col")
contact_network <- network(contact_rate, directed = F, ignore.eval = F, names.eval = "weight")
contact_network%e%"col" <- contact_network%e%"weight" - min(contact_network%e%"weight") + 0.0001
contact_network%e%"col" <- contact_network%e%"col"/max(contact_network%e%"col")
hist(contact_network%e%"col")
min(contact_network%e%"col")
max(contact_network%e%"col")
contact_network%e%"col" <- rgb(0,0,0,1-contact_network%e%"col")
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2, edge.col = "col")
contact_network%e%"col" <- contact_network%e%"weight" - min(contact_network%e%"weight") + 0.0001
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2, edge.col = "col")
rgb(0,0,0,contact_network%e%"col")
contact_network%e%"col" <- rgb(0,0,0,alpha = contact_network%e%"col")
z <- ls_contact$z
z.mean <- apply(z, c(2,3), mean)
contact_network <- network(contact_rate, directed = F, ignore.eval = F, names.eval = "weight")
contact_network%e%"col" <- contact_network%e%"weight" - min(contact_network%e%"weight") + 0.0001
contact_network%e%"col" <- contact_network%e%"col"/max(contact_network%e%"col")
contact_network%e%"col" <- rgb(0,0,0,alpha = contact_network%e%"col")
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2, edge.col = "col")
z <- ls_contact$z
z.mean <- apply(z, c(2,3), mean)
contact_network <- network(contact_rate, directed = F, ignore.eval = F, names.eval = "weight")
contact_network%e%"col" <- contact_network%e%"weight" - min(contact_network%e%"weight") + 0.001
contact_network%e%"col" <- contact_network%e%"col"/max(contact_network%e%"col")
contact_network%e%"col" <- rgb(0,0,0,alpha = contact_network%e%"col")
plot(contact_network, coord = z.mean, edge.lwd = (contact_rate/max(contact_rate))*20 + 1, vertex.cex = 2, edge.col = "col")
z <- MASS::mvrnorm(n = 20, mu = rep(0,2), Sigma = diag(x= 1, nrow = 2))
dist <- as.matrix(dist(z))
kinship <- matrix(rbeta(20*20,1,1),nrow=20,ncol=20)
kinship[upper.tri(kinship)] <- t(kinship)[upper.tri(kinship)]
diag(kinship) <- 0
ind_re <- rnorm(20, mean = 0, sd = 0.2)
re_i <- sapply(ind_re, function(z) rep(z,20))
re_j <- t(re_i)
p <- plogis(-1 - dist + re_i + re_j + 3*kinship)
diag(p) <- 0
d <- matrix(rpois(20*20, 30),nrow = 20, ncol = 20)
d[upper.tri(d)] <- t(d)[upper.tri(d)]
diag(d) <- 0
x <- matrix(rbinom(20*20, size = d, prob = p), nrow = 20, ncol = 20)
x[upper.tri(x)] <- t(x)[upper.tri(x)]
diag(x) <- 0
sri <- x/d
diag(sri) <- 0
m4 <- latent_space(x ~ 1, family = "binomial", ind.RE = F, effort = d)
require(aninet)
m4 <- latent_space(x ~ 1, family = "binomial", ind.RE = F, effort = d)
plot(m4)
plot(z)
plot(z, post.method = "median")
plot(m4, post.method = "median")
plot(m4, post.method = "mean")
plot(m4, post.method = "median")
plot(m4, post.method = "mds")
plot(m4$z[,1])
plot(m4$z[,,1])
plot(m4$z[1,1,])
plot(m4$z[1,,1])
plot(m4$z[,1,1])
plot(m4$z[,2,1])
plot(m4$z[,2,1],type="l")
plot(m4$z[,3,1],type="l")
plot(m4$d[,3,1],type="l")
plot(m4$d[,3,2],type="l")
plot(apply(m4$d,c(2,3),mean) ~ dist)
abline(a = 0, b = 1)
plot(m4, post.method = "mean", vertex.pch = 2)
plot(m4, post.method = "mean", vertex.cex = 2)
plot(m4, post.method = "mean", vertex.cex = 2, fill = "red")
plot(m4, post.method = "mean", vertex.cex = 2, border = "red")
warnings()
?plot.default
plot(m4, post.method = "mean", vertex.cex = 2, bg = "red")
plot(m4, post.method = "mean", vertex.cex = 2, vertex.pch = 1, bg = "red")
plot(m4, post.method = "mean", vertex.cex = 2, vertex.pch = 1, bg = "orange")
plot(m4, post.method = "mean", vertex.cex = 2, vertex.pch = 21, bg = "orange")
points(z, pch = vertex.pch, cex = vertex.cex, col = vertex.col, ...)
plot.latsoc <- function(object, post.method = "mean",
edge.col = NULL, edge.lwd = NULL,
vertex.pch = 19, vertex.col = "black", vertex.cex = 1,
labels = F, label.col = NULL, label.cex = NULL,
...){
n <- nrow(object$response)
if(!post.method %in% c("mean", "median", "mds")){
cat("Invalid post.method, using mean")
cat("\n")
post.method <- "mean"
}
if(dim(object$z)[[3]] > 2){
post.method <- "mds"
}
if(post.method == "mean"){
z <- apply(object$z,c(2,3),mean)
}
if(post.method == "median"){
z <- apply(object$z,c(2,3),median)
}
if(post.method == "mds"){
d <- apply(object$distances, c(2,3), mean)
z <- MASS::isoMDS(as.dist(d))$points
}
rate <- object$response/object$effort
diag(rate) <- 0
if(is.null(edge.col)){
edge.col <- rate - min(rate[rate > 0],na.rm=T) + 0.001
edge.col <- edge.col/max(edge.col,na.rm=T)
edge.col[edge.col < 0] <- 0
edge.col <- matrix(rgb(0,0,0,edge.col),nrow=n,ncol=n)
}
if(is.null(edge.lwd)){
edge.lwd <- rate - min(rate[rate > 0],na.rm=T) + 0.001
edge.lwd <- edge.lwd/max(edge.lwd,na.rm=T)
edge.lwd <- edge.lwd*4
}
plot(z, xlab = "Dimension 1", ylab = "Dimension 2", pch = vertex.pch, cex = vertex.cex, col = vertex.col, ...)
for(i in 1:(n-1)){
for(j in (i+1):n){
if(rate[i,j] > 0){
lines(x = z[c(i,j),1], y = z[c(i,j),2], lwd = edge.lwd[i,j], col = edge.col[i,j])
}
}
}
if(labels){
names <- colnames(object$response)
if(!is.null(names)){
text(x = z[,1], y = z[,2], labels = names, col = label.col, cex = label.cex)
}
}
points(z, pch = vertex.pch, cex = vertex.cex, col = vertex.col, ...)
}
points(z, pch = vertex.pch, cex = vertex.cex, col = vertex.col, ...)
plot(m4, post.method = "mean", vertex.cex = 2, vertex.pch = 21, bg = "orange")
plot(m4, post.method = "mean", vertex.cex = 2, vertex.pch = 21, bg = "orange", lwd = 3)
plot(m4, post.method = "mean", vertex.cex = 2, vertex.pch = 21, bg = "orange", lwd = 2)
plot.latsoc <- function(object, post.method = "mean",
edge.col = NULL, edge.lwd = NULL,
vertex.pch = 21, vertex.col = "black", vertex.cex = 1,
labels = F, label.col = NULL, label.cex = NULL,
...){
n <- nrow(object$response)
if(!post.method %in% c("mean", "median", "mds")){
cat("Invalid post.method, using mean")
cat("\n")
post.method <- "mean"
}
if(dim(object$z)[[3]] > 2){
post.method <- "mds"
}
if(post.method == "mean"){
z <- apply(object$z,c(2,3),mean)
}
if(post.method == "median"){
z <- apply(object$z,c(2,3),median)
}
if(post.method == "mds"){
d <- apply(object$distances, c(2,3), mean)
z <- MASS::isoMDS(as.dist(d))$points
}
rate <- object$response/object$effort
diag(rate) <- 0
if(is.null(edge.col)){
edge.col <- rate - min(rate[rate > 0],na.rm=T) + 0.001
edge.col <- edge.col/max(edge.col,na.rm=T)
edge.col[edge.col < 0] <- 0
edge.col <- matrix(rgb(0,0,0,edge.col),nrow=n,ncol=n)
}
if(is.null(edge.lwd)){
edge.lwd <- rate - min(rate[rate > 0],na.rm=T) + 0.001
edge.lwd <- edge.lwd/max(edge.lwd,na.rm=T)
edge.lwd <- edge.lwd*4
}
plot(z, xlab = "Dimension 1", ylab = "Dimension 2", pch = vertex.pch, cex = vertex.cex, col = vertex.col, ...)
for(i in 1:(n-1)){
for(j in (i+1):n){
if(rate[i,j] > 0){
lines(x = z[c(i,j),1], y = z[c(i,j),2], lwd = edge.lwd[i,j], col = edge.col[i,j])
}
}
}
if(labels){
names <- colnames(object$response)
if(!is.null(names)){
text(x = z[,1], y = z[,2], labels = names, col = label.col, cex = label.cex)
}
}
points(z, pch = vertex.pch, cex = vertex.cex, col = vertex.col, ...)
}
plot(m4, post.method = "mean", vertex.cex = 2)
plot(z, xlim = NULL)
plot.latsoc <- function(object, post.method = "mean",
edge.col = NULL, edge.lwd = NULL,
vertex.pch = 21, vertex.col = "black", vertex.cex = 1,
labels = F, label.col = NULL, label.cex = NULL,
xlim = NULL, ylim = NULL){
n <- nrow(object$response)
if(!post.method %in% c("mean", "median", "mds")){
cat("Invalid post.method, using mean")
cat("\n")
post.method <- "mean"
}
if(dim(object$z)[[3]] > 2){
post.method <- "mds"
}
if(post.method == "mean"){
z <- apply(object$z,c(2,3),mean)
}
if(post.method == "median"){
z <- apply(object$z,c(2,3),median)
}
if(post.method == "mds"){
d <- apply(object$distances, c(2,3), mean)
z <- MASS::isoMDS(as.dist(d))$points
}
rate <- object$response/object$effort
diag(rate) <- 0
if(is.null(edge.col)){
edge.col <- rate - min(rate[rate > 0],na.rm=T) + 0.001
edge.col <- edge.col/max(edge.col,na.rm=T)
edge.col[edge.col < 0] <- 0
edge.col <- matrix(rgb(0,0,0,edge.col),nrow=n,ncol=n)
}
if(is.null(edge.lwd)){
edge.lwd <- rate - min(rate[rate > 0],na.rm=T) + 0.001
edge.lwd <- edge.lwd/max(edge.lwd,na.rm=T)
edge.lwd <- edge.lwd*4
}
plot(z, xlab = "Dimension 1", ylab = "Dimension 2", cex = vertex.cex, bg = vertex.col, pch = 21, ylim = ylim, xlim = xlim)
for(i in 1:(n-1)){
for(j in (i+1):n){
if(rate[i,j] > 0){
lines(x = z[c(i,j),1], y = z[c(i,j),2], lwd = edge.lwd[i,j], col = edge.col[i,j])
}
}
}
if(labels){
names <- colnames(object$response)
if(!is.null(names)){
text(x = z[,1], y = z[,2], labels = names, col = label.col, cex = label.cex)
}
}
points(z, pch = 21, cex = vertex.cex, bg = vertex.col)
}
plot(m4)
plot(m4, vertex.col = "orange")
plot(m4, vertex.col = "red")
plot(m4, vertex.col = "red", vertex.cex = 2)
plot(m4, vertex.col = "red", vertex.cex = 1.2)
plot(m4, vertex.col = "red", vertex.cex = 1.1)
plot(m4, vertex.col = "red", vertex.cex = 1)
plot(m4, vertex.col = "red", vertex.cex = 1.2)
plot(m4, vertex.col = "red", vertex.cex = 1.2, labels = T)
colnames(x)
colnames(m4$response)
m4$response
plot(m4, vertex.col = "red", vertex.cex = 1.2, labels = F)
plot(z0)
plot(z)
m4$summary
plot(ls_plotting) # plot the model fit
#fit a model with only the latent space as a predictor (we'll exclude random effects to speed up fitting)
ls_plotting <- latent_space(srkw_contact ~ 1,
family = "poisson",
dimensions = 2, ind.RE = F,
effort = srkw_sampling,
sample = 50000, burnin = 20000)
plot(ls_plotting) # plot the model fit
=======
}
#get parameter estimates
if(method == "Whitehead"){
result <- stats::optim(initial.params, fn = LL.whitehead, X = X, D = D, delt = res, hessian = T) #MLE for all AIs
}
if(method == "Beta-binomial"){
result <- stats::optim(initial.params, fn = LL.betabinom, X = X, D = D, hessian = T) #MLE for all AIs
}
#transform parameters
a <- exp(result$par[1])
b <- exp(result$par[2])
#calculate mean and standard deviation
mean.fit <- a/(a+b)
sd.fit <- sqrt((a*b)/((a+b)^2*(a+b+1)))
#estimate of social differentiation
estimate <- sd.fit/mean.fit
#observed CV
observed <- stats::sd(X/D)/mean(X/D)
#estimated correlation
correlation <- estimate/observed
#sample parameters based on estimates and hessian matrix
samp <- MASS::mvrnorm(n = 100000, mu = result$par, Sigma = solve(result$hessian))
#distribution of CVs
cv.samp <- apply(samp,1,function(z){
a <- exp(z[1])
b <- exp(z[2])
mean.fit = a/(a+b)
sd.fit = sqrt((a*b)/((a+b)^2*(a+b+1)))
sd.fit/mean.fit
})
#get SEs and CIs
se_S <- sd(cv.samp, na.rm = T)
se_r <- sd(cv.samp/observed, na.rm = T)
ci_S <- quantile(cv.samp, c(0.025,0.975), na.rm = T)
ci_r <- quantile(cv.samp/observed, c(0.025,0.975), na.rm = T)
#make summary table
summary <- matrix(nrow = 3, ncol = 4)
row.names(summary) <- c("Observed CV","Social Differentiation", "Correlation")
colnames(summary) <- c("Estimate", "SE", "Lower CI", "Upper CI")
summary[1,1] <- observed
summary[2,1] <- estimate
summary[2,2] <- se_S
summary[2,c(3,4)] <- ci_S
summary[3,1] <- correlation
summary[3,2] <- se_r
summary[3,c(3,4)] <- ci_r
return(summary)
}
social_differentiation(X,D,method="Whitehead")
social_differentiation(X,D,method="Beta-binomial")
social_differentiation(X,D,method="Beta-binomial")
social_differentiation(X,D,method="Beta-binomial")
social_differentiation(X,D,method="Beta-binomial")
social_differentiation(X,D,method="Whitehead")
#' Generate Null Distributions for Group-by-Individual Data
#'
#' Produce null distributions of target statistics by permuting a group-by-individual matrix using the MCMC routine proposed by Bejder et al. (1998).
#'
#' @param data A group by individual matrix
#' @param ind_constraint A vector of individual characteristics to constrain permutations; defaults to NULL
#' @param group_constraint A vector group characteristics (usually time windows) to constrain permutations; defaults to NULL
#' @param sample The number of samples to draw for each chain. Defaults to 1000.
#' @param thin The number of steps between each draw. Defaults to 100.
#' @param burnin The number of samples before target statistics are calculated. Defaults to 1000.
#' @param chains The number of independent chains to run. Defaults to 2.
#' @param FUN A function taking a GBI as an input and outputting a vector of any length. See Details.
#'
#' @details For some applications, it may be desirable to compare the observed social structure to a null model in which there are no social preferences. This is particularly useful when investigating whether individuals have social preferences, but may also have other uses.
#' In these cases, the canonical method for generating the null model is a Markov Chain Monte Carlo procedure. For each iteration, a change in the matrix is proposed; if the change maintains row an column totals, and falls within the specified constraints, it is accepted, otherwise the matrix stays at its current state.
#' While this method is widely used in social network analysis, and has been implemented in other software, it is often not implemented properly to generate a valid MCMC chain.
#' In addition, none of the current implementations utilize the toolkit that has been developed to check MCMC chain convergence, or provide confidence intervals for p-values. This implementation fills in these gaps.
#'
#' This function takes an argument FUN, which allows users to define custom test statistics. This argument should be a function taking a single argument (the group by individual matrix) and outputting a vector (the test statistic(s)).
#' By default, this function will calculate the test statistics suggested by Whitehead (2008) for testing for non-random social structure: the mean, SD, CV, and portion non-zero association indices (the SRI by default).
#' Other network statistics can be calculated as well (such as clustering coefficient, modularity, etc.).
#'
#' @return An object of class \code{gbi_null}
#'
#' @export
gbi_null <- function(data,
ind_constraint = NULL,
group_constraint = NULL,
samples = 1000,
thin = 100,
burnin = 1000,
chains = 2,
FUN = NULL){
if(!is.matrix(data) | any(!c(data) %in% c(0,1)) | any(is.na(data))){
stop("Data must be a matrix containing only 1s and 0s")
}
N <- ncol(data)
G <- nrow(data)
if(is.null(group_constraint)) group_constraint <- rep(1,G)
if(is.null(ind_constraint)) ind_constraint <- rep(1,N)
if(!is.vector(group_constraint) | length(group_constraint) != G | any(is.na(group_constraint))) stop("group_constraint must be a vector with length equal to the number of groups")
if(!is.vector(ind_constraint) | length(ind_constraint) != N | any(is.na(ind_constraint))) stop("ind_constraint must be a vector with length equal to the number of individuals")
if(is.null(FUN)){
FUN <- function(gbi){
x <- get_numerator(gbi,data_format="GBI",return="vector")
d <- get_denominator(gbi,data_format="GBI",return="vector")
sri <- x/d
res <- c(mean(sri,na.rm=T),sd(sri,na.rm=T),sd(sri,na.rm=T)/mean(sri,na.rm=T),mean(sri > 0, na.rm=T))
names(res) <- c("Mean","SD","CV","Non-zero")
return(res)
}
}
if(!is.function(FUN)) stop("FUN must be a function")
observed <- FUN(data)
chain_res <- list()
for(k in 1:chains){
gbi.p <- data
res_matrix <- matrix(nrow = samples, ncol = length(observed))
colnames(res_matrix) <- names(observed)
for(i in 1:burnin){
for(j in 1:thin){
cols <- sample(N,2)
rows <- sample(G,2)
trial_matrix <- gbi.p[rows,cols]
if( all(rowSums(trial_matrix) == 1) &
all(colSums(trial_matrix) == 1) &
group_constraint[rows[1]] == group_constraint[rows[2]] &
ind_constraint[cols[1]] == ind_constraint[cols[2]]){
trial_matrix <- ifelse(trial_matrix == 1, 0, 1)
gbi.p[rows,cols] <- trial_matrix
}
}
}
for(i in 1:samples){
for(j in 1:thin){
cols <- sample(N,2)
rows <- sample(G,2)
trial_matrix <- gbi.p[rows,cols]
if( all(rowSums(trial_matrix) == 1) &
all(colSums(trial_matrix) == 1) &
group_constraint[rows[1]] == group_constraint[rows[2]] &
ind_constraint[cols[1]] == ind_constraint[cols[2]]){
trial_matrix <- ifelse(trial_matrix == 1, 0, 1)
gbi.p[rows,cols] <- trial_matrix
}
}
res_matrix[i,] <- FUN(gbi.p)
}
chain_res[[k]] <- coda::mcmc(res_matrix, thin = thin, start = thin, end = thin*samples)
}
chain_res <- coda::mcmc.list(chain_res)
results <- list(
FUN = FUN,
observed = observed,
mcmc = chain_res
)
class(results) <- "gbi_null"
return(results)
}
#' Plot Null Distributions for Group-By-Individual Matrices
#'
#' Diagnostic plots for GBI null hypotheses tested with the Manly-Bejder MCMC procedure
#'
#' @param x A \code{gbi_null} object
#'
#' @details This function will first plot the trace plots for the null distributions of each test statistic. It will then plot the change in estimated p-values over the chains.
plot.gbi_null <- function(x){
plot(x$mcmc)
par(mfrow = c(which.min(c(4,length(x$observed))),1))
for(i in 1:length(x$observed)){
for(k in 1:length(x$mcmc)){
pval_gr <- cumsum(x$mcmc[[k]][,i] > x$observed[i])/(1:length(x$mcmc[[k]][,i]))
if(k == 1){
plot(pval_gr, main = names(x$observed)[i], type = "l", col = k, xlab = "Iteration", ylab = "P(Random > Observed)", ylim = c(0,1))
}else{
points(pval_gr, type = "l", col = k)
}
}
}
}
require(aninet)
test <- gbi_null(srkw_sampling, samples = 100, thin = 10, burnin = 10)
srkw_sampling
test <- gbi_null(srkw_sightings, samples = 100, thin = 10, burnin = 10)
plot(test)
plot(test)
par(mar = c(4,4,1,1))
plot(test)
data <- matrix(rbinom(n = 40*200, size = 1, prob = 0.1) ,nrow = 200, ncol = 40)
test <- gbi_nulldata, samples = 100, thin = 10, burnin = 10)
test <- gbi_null(data, samples = 100, thin = 10, burnin = 10)
plot(test)
test <- gbi_null(data, samples = 1000, thin = 100, burnin = 100, chains = 4)
plot(test)
gbi_MCMC <- function(data,
ind_constraint = NULL,
group_constraint = NULL,
samples = 1000,
thin = 100,
burnin = 1000,
chains = 2,
FUN = NULL){
if(!is.matrix(data) | any(!c(data) %in% c(0,1)) | any(is.na(data))){
stop("Data must be a matrix containing only 1s and 0s")
}
N <- ncol(data)
G <- nrow(data)
if(is.null(group_constraint)) group_constraint <- rep(1,G)
if(is.null(ind_constraint)) ind_constraint <- rep(1,N)
if(!is.vector(group_constraint) | length(group_constraint) != G | any(is.na(group_constraint))) stop("group_constraint must be a vector with length equal to the number of groups")
if(!is.vector(ind_constraint) | length(ind_constraint) != N | any(is.na(ind_constraint))) stop("ind_constraint must be a vector with length equal to the number of individuals")
if(is.null(FUN)){
FUN <- function(gbi){
x <- get_numerator(gbi,data_format="GBI",return="vector")
d <- get_denominator(gbi,data_format="GBI",return="vector")
sri <- x/d
res <- c(mean(sri,na.rm=T),sd(sri,na.rm=T),sd(sri,na.rm=T)/mean(sri,na.rm=T),mean(sri > 0, na.rm=T))
names(res) <- c("Mean","SD","CV","Non-zero")
return(res)
}
}
if(!is.function(FUN)) stop("FUN must be a function")
observed <- FUN(data)
chain_res <- list()
for(k in 1:chains){
gbi.p <- data
res_matrix <- matrix(nrow = samples, ncol = length(observed))
colnames(res_matrix) <- names(observed)
for(i in 1:burnin){
for(j in 1:thin){
cols <- sample(N,2)
rows <- sample(G,2)
trial_matrix <- gbi.p[rows,cols]
if( all(rowSums(trial_matrix) == 1) &
all(colSums(trial_matrix) == 1) &
group_constraint[rows[1]] == group_constraint[rows[2]] &
ind_constraint[cols[1]] == ind_constraint[cols[2]]){
trial_matrix <- ifelse(trial_matrix == 1, 0, 1)
gbi.p[rows,cols] <- trial_matrix
}
}
}
for(i in 1:samples){
for(j in 1:thin){
cols <- sample(N,2)
rows <- sample(G,2)
trial_matrix <- gbi.p[rows,cols]
if( all(rowSums(trial_matrix) == 1) &
all(colSums(trial_matrix) == 1) &
group_constraint[rows[1]] == group_constraint[rows[2]] &
ind_constraint[cols[1]] == ind_constraint[cols[2]]){
trial_matrix <- ifelse(trial_matrix == 1, 0, 1)
gbi.p[rows,cols] <- trial_matrix
}
}
res_matrix[i,] <- FUN(gbi.p)
}
chain_res[[k]] <- coda::mcmc(res_matrix, thin = thin, start = thin, end = thin*samples)
}
chain_res <- coda::mcmc.list(chain_res)
results <- list(
FUN = FUN,
observed = observed,
mcmc = chain_res
)
class(results) <- "gbi_null"
return(results)
}
test <- gbi_null(data, samples = 10000, thin = 100, burnin = 100, chains = 4)
plot(test)
gelman.diag(x$mcmc)
require(coda)
gelman.diag(x$mcmc)
gelman.diag(test$mcmc)
mcmcse::ess(test$mcmc[[1]])
mcmcse::ess(test$mcmc[[2]])
?ess
ess_mean <- mcmcse::ess(test$mcmc)
ess_mean
x <- test
psrf <- coda::gelman.diag(x$mcmc,multivariate = F)
ess_mean <- mcmcse::ess(x$mcmc)
ess_pval <- mcmcse::ess(x$mcmc, g = function(z){
z > x$observed
})
ess_pval <- lapply(x$mcmc, function(y){
mcmcse::ess(y, g = function(z){
z > x$observed
})
})
ess_pval
ess_pval <- lapply(x$mcmc, function(y){
mcmcse::ess(y, g = function(z){
ifelse(z > x$observed,1,0)
})
})
ess_pval
mcmcse::ess(x$mcmc)
mcmcse::ess(x$mcmc[[1]])
mcmcse::ess(x$mcmc[[2]])
mcmcse::ess(x$mcmc[[3]])
plot(ifelse(x$mcmc[[1]][,1] > x$observed[1], 1, 0))
plot(ifelse(x$mcmc[[1]][,1] > x$observed[1], 1, 0), type = "l")
acf(ifelse(x$mcmc[[1]][,1] > x$observed[1], 1, 0))
pval_matrices <- lapply(x$mcmc, function(y){
apply(y, 1, function(z){
ifelse(z > x$observed, 1, 0)
})
})
pval_matrices[[1]]
pval_matrices <- lapply(x$mcmc, function(y){
t(apply(y, 1, function(z){
ifelse(z > x$observed, 1, 0)
}))
})
ess(pval_matrices)
mcmcse::ess(pval_matrices)
pval_matrices[[1]]
pval_matrices <- mcmc.list(lapply(x$mcmc, function(y){
mcmc(t(apply(y, 1, function(z){
ifelse(z > x$observed, 1, 0)
})))
}))
ess(pval_matrices)
require(mcmcse)
ess(pval_matrices)
ess_pval <- mcmcse::ess(pval_matrices)
ess_pval
p_gr <- sapply(length(x$observed), function(z){
mean(all_mcmc[,z] > x$observed[z])
})
all_mcmc <- do.call(rbind, x$mcmc)
p_gr <- sapply(length(x$observed), function(z){
mean(all_mcmc[,z] > x$observed[z])
})
p_ls <- sapply(length(x$observed), function(z){
mean(all_mcmc[,z] < x$observed[z])
})
p_twotail <- sapply(1:length(x$observed), function(z){
min(c(p_gr[z],p_ls[z]))*2
})
p_gr
p_ls
p_twotailed
p_twotail
x$observed
p_gr <- sapply(length(x$observed), function(z){
mean(all_mcmc[,z] > x$observed[z])
})
p_gr
p_gr <- sapply(1:length(x$observed), function(z){
mean(all_mcmc[,z] > x$observed[z])
})
p_ls <- sapply(1:length(x$observed), function(z){
mean(all_mcmc[,z] < x$observed[z])
})
p_twotail <- sapply(1:length(x$observed), function(z){
min(c(p_gr[z],p_ls[z]))*2
})
p_twotail
p_gr
p_ls
require(binom)
ci_gr <- binom.confint(p_gr*ess_pval, ess_pval, method = "exact")
ci_gr
ci_gr <- binom.confint(p_gr*ess_pval, ess_pval, method = "exact")
ci_ls <- binom.confint(p_ls*ess_pval, ess_pval, method = "exact")
ci_tt <- binom.confint(p_twotail*ess_pval, ess_pval, method = "exact")
ci_tt
ci_gr <- binom::binom.confint(p_gr*ess_pval, ess_pval, method = "exact")[,5:6]
ci_ls <- binom::binom.confint(p_ls*ess_pval, ess_pval, method = "exact")[,5:6]
ci_tt <- binom::binom.confint(p_twotail*ess_pval, ess_pval, method = "exact")[,5:6]
ci_gr
upper_summary <- cbind(p_gr,ci_gr)
lower_summary <- cbind(p_ls,ci_ls)
twotail_summary <- cbind(p_twotail,ci_tt)
colnames(upper_summary) <- colnames(lower_summary) <- colnames(twotail_summary) <- c("P-Value","95% UCI","95% LCI")
row.names(upper_summary) <- row.names(lower_summary) <- row.names(twotail_summary) <- names(x$observed)
HPDinterval(x$mcmc)
summary(x$mcmc)
cat("P(Random > Observed)"m"\n")
cat("P(Random > Observed)","\n")
print(upper_summary)
cat("\n")
cat("P(Random > Observed)","\n")
print(upper_summary)
cat("\n")
cat("P(Random < Observed)","\n")
print(lower_summary)
cat("\n")
cat("Two-Tailed P-values","\n")
print(twotail_summary)
cat("\n")
upper_summary <- cbind(p_gr,ci_gr,ess_pval)
lower_summary <- cbind(p_ls,ci_ls,ess_pval)
twotail_summary <- cbind(p_twotail,ci_tt,ess_pval)
colnames(upper_summary) <- colnames(lower_summary) <- colnames(twotail_summary) <- c("P-Value","95% UCI","95% LCI","ESS")
row.names(upper_summary) <- row.names(lower_summary) <- row.names(twotail_summary) <- names(x$observed)
cat("P(Random > Observed)","\n")
print(upper_summary)
cat("\n")
cat("P(Random < Observed)","\n")
print(lower_summary)
cat("\n")
cat("Two-Tailed P-values","\n")
print(twotail_summary)
hpdi <- HPDinterval(all_mcmc)
hpdi <- HPDinterval(as.mcmc(all_mcmc))
hpdi
hpdi <- as.matrix(HPDinterval(as.mcmc(all_mcmc)))
hpdi
attr(hpdi)
attr(hpdi,"Probability")
summary(x$mcmc)
psrf(pval_matrices)
gelman.diag(pval_matrices)
pval_matrices <- coda::mcmc.list(lapply(x$mcmc, function(y){
coda::mcmc(t(apply(y, 1, function(z){
ifelse(z > x$observed, 1, 0)
})))
}))
gelman.diag(pval_matrices)
psrf
null_means <- colMeans(all_mcmc)
null_median <- apply(all_mcmc,2,median)
null_sd <- apply(all_mcmc,2,sd)
hpdi <- coda::HPDinterval(as.mcmc(all_mcmc))
hpdi
cbind(x$observed,null_means,null_median,null_sd,hpdi)
colnames(dist_summary) <- c("Observed", "Random Mean", "Random Median", "Random SD", "Random 95% LCI", "Ranomd 95% UCI")
dist_summary <- cbind(x$observed,null_means,null_median,null_sd,hpdi)
colnames(dist_summary) <- c("Observed", "Random Mean", "Random Median", "Random SD", "Random 95% LCI", "Random 95% UCI")
dist_summary
colnames(dist_summary) <- c("Observed", "Null Mean", "Null Median", "Null SD", "Null 95% LCI", "Null 95% UCI")
dist_summary
hpdi <- apply(all_mcmc,2,quantile,probs=c(0.025,0.975))
CI <- apply(all_mcmc,2,quantile,probs=c(0.025,0.975))
CI
CI <- t(apply(all_mcmc,2,quantile,probs=c(0.025,0.975)))
dist_summary <- cbind(x$observed,null_means,null_median,null_sd,CI)
colnames(dist_summary) <- c("Observed", "Null Mean", "Null Median", "Null SD", "Null 95% LCI", "Null 95% UCI")
dist_summary
summary.gbi_null <- function(x){
psrf <- coda::gelman.diag(x$mcmc,multivariate = F)
ess_mean <- mcmcse::ess(x$mcmc)
null_means <- colMeans(all_mcmc)
null_median <- apply(all_mcmc,2,median)
null_sd <- apply(all_mcmc,2,sd)
CI <- t(apply(all_mcmc,2,quantile,probs=c(0.025,0.975)))
dist_summary <- cbind(x$observed,null_means,null_median,null_sd,CI)
colnames(dist_summary) <- c("Observed", "Null Mean", "Null Median", "Null SD", "Null 95% LCI", "Null 95% UCI")
cat("Null Distribution", "\n")
print(dist_summary)
cat("\n")
pval_matrices <- coda::mcmc.list(lapply(x$mcmc, function(y){
coda::mcmc(t(apply(y, 1, function(z){
ifelse(z > x$observed, 1, 0)
})))
}))
ess_pval <- mcmcse::ess(pval_matrices)
all_mcmc <- do.call(rbind, x$mcmc)
p_gr <- sapply(1:length(x$observed), function(z){
mean(all_mcmc[,z] > x$observed[z])
})
p_ls <- sapply(1:length(x$observed), function(z){
mean(all_mcmc[,z] < x$observed[z])
})
p_twotail <- sapply(1:length(x$observed), function(z){
min(c(p_gr[z],p_ls[z]))*2
})
ci_gr <- binom::binom.confint(p_gr*ess_pval, ess_pval, method = "exact")[,5:6]
ci_ls <- binom::binom.confint(p_ls*ess_pval, ess_pval, method = "exact")[,5:6]
ci_tt <- binom::binom.confint(p_twotail*ess_pval, ess_pval, method = "exact")[,5:6]
upper_summary <- cbind(p_gr,ci_gr,ess_pval)
lower_summary <- cbind(p_ls,ci_ls,ess_pval)
twotail_summary <- cbind(p_twotail,ci_tt,ess_pval)
colnames(upper_summary) <- colnames(lower_summary) <- colnames(twotail_summary) <- c("P-Value","95% UCI","95% LCI","ESS")
row.names(upper_summary) <- row.names(lower_summary) <- row.names(twotail_summary) <- names(x$observed)
cat("P(Random > Observed)","\n")
print(upper_summary)
cat("\n")
cat("P(Random < Observed)","\n")
print(lower_summary)
cat("\n")
cat("Two-Tailed P-values","\n")
print(twotail_summary)
cat("\n")
}
summary(test)
dist_summary <- cbind(x$observed,null_means,null_median,null_sd,CI,ess_mean,psrf)
colnames(dist_summary) <- c("Observed", "Null Mean", "Null Median", "Null SD", "Null 95% LCI", "Null 95% UCI","ESS","PSRF")
cat("Null Distribution", "\n")
print(dist_summary)
psrf <- coda::gelman.diag(x$mcmc,multivariate = F)
psrf
psrf <- coda::gelman.diag(x$mcmc,multivariate = F)[,1]
psrf <- coda::gelman.diag(x$mcmc,multivariate = F)[[1]][,1]
psrf
ess_mean <- mcmcse::ess(x$mcmc)
null_means <- colMeans(all_mcmc)
null_median <- apply(all_mcmc,2,median)
null_sd <- apply(all_mcmc,2,sd)
CI <- t(apply(all_mcmc,2,quantile,probs=c(0.025,0.975)))
dist_summary <- cbind(x$observed,null_means,null_median,null_sd,CI,ess_mean,psrf)
colnames(dist_summary) <- c("Observed", "Null Mean", "Null Median", "Null SD", "Null 95% LCI", "Null 95% UCI","ESS","PSRF")
cat("Null Distribution", "\n")
print(dist_summary)
cat("\n")
dist_summary <- cbind(null_means,null_median,null_sd,CI,ess_mean,psrf)
colnames(dist_summary) <- c("Mean", "Median", "SD", "95% LCI", "95% UCI","ESS","PSRF")
cat("Null Distribution", "\n")
print(dist_summary)
library(aninet)
?gbi_MCMC
library(aninet)
library(aninet)
library(aninet)
aninet::gbi_MCMC(aninet::srkw_sightings)
>>>>>>> d3f2a324e2354e518d1f383157d4ee968c5b3701
